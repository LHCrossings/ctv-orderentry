"""
Order Detection Service - Pure business logic for identifying order types.

This service separates the detection logic from file I/O. The detection
logic is pure string matching - given text content, return the order type.
"""

import re
import sys
from pathlib import Path
from typing import Protocol

# Add src to path for absolute imports
_src_path = Path(__file__).parent.parent.parent
if str(_src_path) not in sys.path:
    sys.path.insert(0, str(_src_path))

from domain.enums import OrderType


class TextExtractor(Protocol):
    """
    Protocol defining how to extract text from PDFs.

    This allows the service to work with any PDF library without
    tight coupling to pdfplumber.
    """

    def extract_text(self, page_number: int) -> str:
        """Extract text from a specific page (0-indexed)."""
        ...

    def get_page_count(self) -> int:
        """Get total number of pages in PDF."""
        ...


class OrderDetectionService:
    """
    Pure business logic for detecting order types from PDF text.

    This service contains no file I/O - it works with text strings.
    All detection patterns are encoded as methods for easy testing
    and modification.
    """

    def detect_from_text(
        self,
        first_page_text: str,
        second_page_text: str | None = None
    ) -> OrderType:
        """
        Detect order type from extracted PDF text.

        This is the main detection method - pure business logic with
        no side effects. Given text, return the detected type.

        Args:
            first_page_text: Text content from first page
            second_page_text: Optional text content from second page

        Returns:
            Detected OrderType enum value

        Examples:
            >>> service = OrderDetectionService()
            >>> text = "WL Tracking No. 12345\\nAgency:Tatari"
            >>> service.detect_from_text(text)
            OrderType.WORLDLINK
        """
        # Detection order matters! More specific checks first

        # SAGENT (check early - distinctive GaleForceMedia marker)
        if self._is_sagent(first_page_text):
            return OrderType.SAGENT

        # Daviselen (check first - has unique markers)
        if self._is_daviselen(first_page_text, second_page_text):
            return OrderType.DAVISELEN

        # WorldLink (check early - common and distinctive)
        if self._is_worldlink(first_page_text):
            return OrderType.WORLDLINK

        # H&L Partners (before TCAA - both use CRTV)
        if self._is_hl_partners(first_page_text):
            return OrderType.HL

        # TCAA (specific CRTV-Cable marker)
        if self._is_tcaa(first_page_text):
            return OrderType.TCAA

        # opAD
        if self._is_opad(first_page_text):
            return OrderType.OPAD

        # Misfit
        if self._is_misfit(first_page_text):
            return OrderType.MISFIT

        # Impact Marketing
        if self._is_impact(first_page_text):
            return OrderType.IMPACT

        # iGraphix
        if self._is_igraphix(first_page_text):
            return OrderType.IGRAPHIX

        # Admerasia
        if self._is_admerasia(first_page_text):
            return OrderType.ADMERASIA

        # RPM
        if self._is_rpm(first_page_text):
            return OrderType.RPM

        return OrderType.UNKNOWN

    def _is_sagent(self, text: str) -> bool:
        """
        Check if text matches SAGENT order patterns.

        SAGENT patterns:
        - "Sagent" (company name)
        - "generated by GaleForceMedia" (PDF generator)
        - "2215 21st St" + "Sacramento, CA 95818" (address)
        - "sagentmarketing.com" (website)

        Require at least 2 markers for confident detection.
        """
        sagent_markers = [
            "Sagent",
            "generated by GaleForceMedia",
            "2215 21st St",
            "Sacramento, CA 95818",
            "sagentmarketing.com"
        ]

        marker_count = sum(1 for marker in sagent_markers if marker in text)
        return marker_count >= 2

    def _is_daviselen(
        self,
        first_page: str,
        second_page: str | None
    ) -> bool:
        """
        Check if text matches Daviselen order patterns.

        Daviselen patterns:
        - "DAVIS ELEN" or "DAVISELEN" anywhere
        - "Brand Time Schedule - CLAN" on page 2
        """
        first_upper = first_page.upper()

        if "DAVIS ELEN" in first_upper or "DAVISELEN" in first_upper:
            return True

        if second_page:
            second_upper = second_page.upper()
            if "DAVIS ELEN" in second_upper or "DAVISELEN" in second_upper:
                return True
            # Check for unique format
            if "Brand Time Schedule" in second_page and "CLAN" in second_page:
                return True

        return False

    def _is_worldlink(self, text: str) -> bool:
        """
        Check if text matches WorldLink order patterns.

        WorldLink patterns:
        - "WL Tracking No."
        - "Unwired Tracking No."
        - "Agency:Tatari"
        - "c/o WorldLink"
        - "WorldLink Ventures"
        """
        patterns = [
            "WL Tracking No.",
            "Unwired Tracking No.",
            "Agency:Tatari",
            "c/o WorldLink",
            "WorldLink Ventures"
        ]
        return any(pattern in text for pattern in patterns)

    def _is_hl_partners(self, text: str) -> bool:
        """
        Check if text matches H&L Partners order patterns.

        H&L Partners patterns:
        - "H/L Agency" or "H/L Agency San Francisco"
        - CRTV-TV (not CRTV-Cable) + Sacramento/San Francisco + Estimate
        - Encoding-damaged variants: "HL Agency", "H Agency"

        Note: Must check before TCAA since both use CRTV
        """
        # Direct H&L agency mention
        if "H/L Agency" in text or "H/L Agency San Francisco" in text:
            return True

        # H&L variant detection for PDFs with encoding issues
        text_upper = text.upper()
        has_crtv = "CRTV-TV" in text or "CRTV" in text_upper
        has_estimate = "Estimate:" in text
        has_location = any(loc in text or loc in text_upper for loc in [
            "Sacramento", "San Francisco",
            "SACRAMENTO", "SAN FRANCISCO"
        ])

        if has_crtv and has_estimate and has_location:
            # Additional check: NOT TCAA (TCAA uses CRTV-Cable)
            if "CRTV-Cable" not in text:
                # Check for H&L-specific markers
                hl_markers = [
                    "Send Billing",
                    "HL Agency",
                    "H Agency",
                    "Agency San Francisco"
                ]
                if any(marker in text for marker in hl_markers):
                    return True

        return False

    def _is_tcaa(self, text: str) -> bool:
        """
        Check if text matches TCAA order patterns.

        TCAA patterns:
        - "CRTV-Cable" (not CRTV-TV) + "Estimate:"
        """
        return "CRTV-Cable" in text and "Estimate:" in text

    def count_tcaa_orders(self, text: str) -> int:
        """
        Count the number of TCAA orders in a PDF.

        TCAA PDFs can have multiple orders, each with its own "Estimate: XXXX".

        Args:
            text: Full PDF text (all pages)

        Returns:
            Number of distinct orders found
        """
        import re

        # Find all estimate numbers
        estimate_pattern = r'Estimate:\s*(\d+)'
        estimates = re.findall(estimate_pattern, text)

        # Return count of unique estimate numbers
        return len(set(estimates))

    def split_tcaa_orders(self, full_text: str) -> list[dict[str, str]]:
        """
        Split a multi-order TCAA PDF into individual orders.

        FIXED: Filters out summary pages instead of grouping by estimate number.

        Args:
            full_text: Complete text from all pages of PDF

        Returns:
            List of dicts with 'estimate' and 'text' for each order
        """
        import re

        # Find all estimate numbers and split at each occurrence
        estimate_pattern = r'Estimate:\s*(\d+)'

        # Find all estimates
        all_estimates = re.findall(estimate_pattern, full_text)

        if not all_estimates:
            return [{'estimate': 'Unknown', 'text': full_text}]

        # Split text at each "Estimate:" marker (keeping the marker with the text)
        parts = re.split(r'(?=Estimate:\s*\d+)', full_text)

        sections = []

        # Process each part
        for part in parts:
            if not part.strip():
                continue

            # Extract estimate number from this section
            est_match = re.search(estimate_pattern, part)
            if not est_match:
                continue

            estimate_num = est_match.group(1)

            # CRITICAL FIX: Determine if this is a schedule page or summary page
            # Schedule pages have actual line items and "SCHEDULE TOTALS"
            has_schedule = (
                'SCHEDULE TOTALS' in part or
                'Station Total:' in part or
                part.count('CRTV-Cable') > 3  # Has multiple line items
            )

            # Summary pages only have aggregate data
            is_summary = (
                'Summary by Market' in part or
                'Summary by Station/System' in part
            )

            # Only include sections with actual schedule data (not summaries)
            if has_schedule and not is_summary:
                sections.append({
                    'estimate': estimate_num,
                    'text': part
                })

        # Return filtered sections
        if sections:
            return sections

        # Fallback: if we filtered everything out, return unique estimates
        unique_estimates = sorted(set(all_estimates))
        return [{'estimate': est, 'text': full_text} for est in unique_estimates]


    def _is_opad(self, text: str) -> bool:
        """
        Check if text matches opAD order patterns.

        opAD patterns:
        - "Estimate:" + "# of SPOTS PER WEEK"
        """
        return "Estimate:" in text and "# of SPOTS PER WEEK" in text

    def _is_misfit(self, text: str) -> bool:
        """
        Check if text matches Misfit order patterns.

        Misfit patterns:
        - "Agency: Misfit"
        - "@agencymisfit.com"
        - "Misfit" + "Crossings TV"
        Must have "Language Block" column header
        """
        has_misfit = (
            "Agency: Misfit" in text or
            "@agencymisfit.com" in text or
            ("Misfit" in text and "Crossings TV" in text)
        )
        has_language_block = "Language Block" in text

        return has_misfit and has_language_block

    def _is_impact(self, text: str) -> bool:
        """
        Check if text matches Impact Marketing order patterns.

        Impact patterns:
        - "Impact Marketing" or "Big Valley Ford" or "@impactcalifornia.com"
        Must have quarterly structure (Q1-, Q2-, etc.) or Crossings TV + Central Valley
        """
        has_impact = (
            "Impact Marketing" in text or
            "Big Valley Ford" in text or
            "@impactcalifornia.com" in text
        )

        has_quarterly = any(q in text for q in ["Q1-", "Q2-", "Q3-", "Q4-"])
        has_crossings_cv = "Crossings TV" in text and "Central Valley" in text

        return has_impact and (has_quarterly or has_crossings_cv)

    def _is_igraphix(self, text: str) -> bool:
        """
        Check if text matches iGraphix order patterns.

        iGraphix patterns:
        - "iGraphix" or "IGraphix"
        Must have known clients (Pechanga, Sky River) or c/o + Crossings TV
        """
        has_igraphix = "iGraphix" in text or "IGraphix" in text

        has_client = (
            "Pechanga" in text or
            "Sky River" in text or
            ("c/o" in text and "Crossings TV" in text)
        )

        return has_igraphix and has_client

    def _is_admerasia(self, text: str) -> bool:
        """
        Check if text matches Admerasia order patterns.

        Admerasia patterns:
        - "Admerasia" or "ADMERASIA"
        Must have McDonald's or Order Number format (XX-MDXX-XXXXXX)
        """
        text_upper = text.upper()
        has_admerasia = "Admerasia" in text or "ADMERASIA" in text_upper

        if not has_admerasia:
            return False

        # Check for McDonald's
        if "McDonald" in text or "Ref: McDonald" in text:
            return True

        # Check for order number format with MD
        if "Order Number:" in text and "-MD" in text:
            return True

        return False

    def _is_rpm(self, text: str) -> bool:
        """
        Check if text matches RPM order patterns.

        RPM patterns:
        - "RPM" in first 300 characters
        - Seattle-Tacoma/Sacramento-Stockton/San Francisco + Estimate + specific header
        """
        # Check header (first 300 chars)
        header = text[:300]
        if "RPM" in header:
            return True

        # Check for market-specific patterns
        # "Sacramento-Stockton" for clean text; "Sacramento" alone for OCR output
        has_market = any(market in text for market in [
            "Seattle-Tacoma",
            "Sacramento-Stockton",
            "Sacramento",
            "San Francisco"
        ])
        has_estimate = "Estimate:" in text
        # Any Crossings TV station header (Seattle, Sacramento, SFO vary)
        has_header = "CROSSINGS TV" in text.upper()

        return has_market and has_estimate and has_header

    def has_encoding_issues(self, text: str) -> bool:
        """
        Check if PDF text has severe encoding issues.

        PDFs with encoding issues show CID (Character ID) markers
        instead of readable text.

        Returns:
            True if text has more than 20 CID markers
        """
        return "(cid:" in text and text.count("(cid:") > 20

    def extract_client_name(
        self,
        first_page_text: str,
        second_page_text: str | None,
        order_type: OrderType
    ) -> str | None:
        """
        Extract client/advertiser name from PDF text based on order type.

        Each agency has different patterns for client names.

        Args:
            first_page_text: Text from first page
            second_page_text: Optional text from second page
            order_type: Detected order type

        Returns:
            Client name if found, None otherwise
        """
        # Agency-specific extraction patterns
        if order_type == OrderType.SAGENT:
            return self._extract_sagent_client(first_page_text)

        elif order_type == OrderType.WORLDLINK:
            return self._extract_worldlink_client(first_page_text)

        elif order_type == OrderType.TCAA:
            return self._extract_tcaa_client(first_page_text)

        elif order_type == OrderType.OPAD:
            return self._extract_opad_client(first_page_text)

        elif order_type == OrderType.HL:
            return self._extract_hl_client(first_page_text)

        elif order_type == OrderType.DAVISELEN:
            return self._extract_daviselen_client(first_page_text, second_page_text)

        elif order_type == OrderType.MISFIT:
            return self._extract_misfit_client(first_page_text)

        elif order_type == OrderType.IGRAPHIX:
            return self._extract_igraphix_client(first_page_text)

        # Fallback: try common patterns
        return self._extract_generic_client(first_page_text)

    def _extract_sagent_client(self, text: str) -> str | None:
        """
        Extract client from SAGENT order - look for 'ADVERTISER:' field.

        SAGENT format: "ADVERTISER: CAL FIRE REV: 0"
        Need to strip the "REV: 0" suffix.
        """
        match = re.search(r'ADVERTISER:\s*([^\n]+)', text, re.IGNORECASE)
        if match:
            client = match.group(1).strip()
            # Remove "REV: #" suffix if present
            client = re.sub(r'\s+REV:\s*\d+\s*$', '', client, flags=re.IGNORECASE)
            return client.strip()
        return None

    def _extract_worldlink_client(self, text: str) -> str | None:
        """Extract client from WorldLink order - look for 'Advertiser:' field."""
        match = re.search(r'Advertiser:\s*([^\n]+)', text)
        return match.group(1).strip() if match else None

    def _extract_tcaa_client(self, text: str) -> str | None:
        """
        Extract client from TCAA order.

        TCAA orders typically have the client name on a line,
        sometimes followed by "Estimate:" on the same or next line.
        """
        # Try "Client:" pattern first
        match = re.search(r'Client:\s*([^\n]+)', text)
        if match:
            client = match.group(1).strip()
            # Remove estimate if it's on the same line
            client = re.sub(r'\s*Estimate:.*$', '', client)
            return client

        # TCAA specific: Look for pattern after "CRTV-Cable"
        # Client name usually appears after the header
        match = re.search(r'CRTV-Cable[^\n]*\n\s*Estimate:\s*\d+[^\n]*\n\s*([^\n]+)', text)
        if match:
            client = match.group(1).strip()
            # Clean up - remove any trailing estimate references
            client = re.sub(r'\s*Estimate:.*$', '', client)
            return client

        # Fallback: generic extraction
        return self._extract_generic_client(text)

    def _extract_opad_client(self, text: str) -> str | None:
        """Extract client from opAD order - look for 'Client:' field."""
        match = re.search(r'Client:\s*([^\n]+)', text)
        return match.group(1).strip() if match else None

    def _extract_hl_client(self, text: str) -> str | None:
        """
        Extract client from H&L Partners order.

        H&L has fixed customer: Northern CA Dealers Association
        """
        match = re.search(r'Client:\s*([^\n]+?)(?:\s+Estimate:|\s+Vendor:)', text)
        if match:
            return match.group(1).strip()
        # Default for H&L
        return "Northern California Dealers Association"

    def _extract_daviselen_client(
        self,
        first_page: str,
        second_page: str | None
    ) -> str | None:
        """
        Extract client from Daviselen order.

        Look on page 1 for 'Client', or page 2 for 'CLIENT'
        """
        # Try page 1
        match = re.search(r'Client\s+([^\n]+?)(?:\n|Product)', first_page)
        if match:
            return match.group(1).strip()

        # Try page 2 if available
        if second_page:
            match = re.search(r'CLIENT\s+([A-Z]+)\s+(.+?)\s+Market', second_page)
            if match:
                return match.group(2).strip()

        return None

    def _extract_misfit_client(self, text: str) -> str | None:
        """Extract client from Misfit order - look for 'Contact:' field."""
        match = re.search(r'Contact:\s*([^\n]+)', text)
        return match.group(1).strip() if match else None

    def _extract_igraphix_client(self, text: str) -> str | None:
        """
        Extract client from iGraphix order.

        Pattern: "Advertiser: IGraphix c/o <client>" where client is one line.
        """
        match = re.search(
            r'Advertiser:.*?c/o\s+([^\n]+)',
            text,
            re.DOTALL | re.IGNORECASE
        )
        if match:
            client = match.group(1).strip()
            return client
        return None

    def _extract_generic_client(self, text: str) -> str | None:
        """
        Fallback client extraction using common patterns.

        Tries: Client:, Advertiser:, Customer:
        """
        patterns = [
            r'Client:\s*([^\n]+)',
            r'Advertiser:\s*([^\n]+)',
            r'Customer:\s*([^\n]+)'
        ]

        for pattern in patterns:
            match = re.search(pattern, text)
            if match:
                return match.group(1).strip()

        return None


def create_detection_service():
    """
    Factory function to create a fully configured PDFOrderDetector.

    Returns:
        Configured PDFOrderDetector instance (wraps OrderDetectionService)
    """
    from .pdf_order_detector import PDFOrderDetector
    return PDFOrderDetector(OrderDetectionService())
